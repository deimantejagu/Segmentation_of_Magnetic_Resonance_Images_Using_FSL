{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/pedrohtg/weasel/blob/main/weasel_ft_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14309,
     "status": "ok",
     "timestamp": 1747841020597,
     "user": {
      "displayName": "Deimantė Ja",
      "userId": "18204054727300762578"
     },
     "user_tz": -180
    },
    "id": "Vuv0XFpHSJdE",
    "outputId": "a2b4ce9e-7554-42c6-f88d-6868dfea8806"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "\n",
    "%cd /content/drive/MyDrive/Colab Notebooks/Bakalauras/SPSMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ssxSL0XJmkIB"
   },
   "outputs": [],
   "source": [
    "!pip install SimpleITK nibabel pillow tqdm nilearn\n",
    "!pip install torchmeta --no-deps\n",
    "!pip install ordered_set --no-deps\n",
    "!pip install torchvision --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 4072,
     "status": "ok",
     "timestamp": 1747841623526,
     "user": {
      "displayName": "Deimantė Ja",
      "userId": "18204054727300762578"
     },
     "user_tz": -180
    },
    "id": "N_rp2EuqPTSR"
   },
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "\n",
    "# Custom implementations of the torchmeta required functions\n",
    "def _get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith('download_warning'):\n",
    "            return value\n",
    "    return None\n",
    "\n",
    "def _save_response_content(response, destination):\n",
    "    chunk_size = 32768\n",
    "    with open(destination, 'wb') as f:\n",
    "        for chunk in response.iter_content(chunk_size):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "\n",
    "!sed -i 's/from torchvision.datasets.utils import _get_confirm_token, _save_response_content//' /usr/local/lib/python3.11/dist-packages/torchmeta/datasets/utils.py\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn import metrics\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch import nn\n",
    "from torchmeta import modules\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "dataset_root = 'dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 5413,
     "status": "ok",
     "timestamp": 1747841744440,
     "user": {
      "displayName": "Deimantė Ja",
      "userId": "18204054727300762578"
     },
     "user_tz": -180
    },
    "id": "gaPJJtQE84Kr"
   },
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class ListDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset class to load images and corresponding masks for training or testing.\n",
    "\n",
    "    This class supports various annotation sparsity modes such as 'points' and 'grid', allowing for few-shot\n",
    "    learning tasks. It pairs images with their respective masks and applies optional resizing and sparsity transformations.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mode, dataset_root, task, fold, resize_to, num_shots, sparsity_mode, sparsity_param, imgtype, make=True):\n",
    "        \"\"\"\n",
    "        Initialize the ListDataset.\n",
    "\n",
    "        Args:\n",
    "            mode (str): Dataset usage mode - 'train', 'test', 'tune_train', or 'tune_test'.\n",
    "            dataset_root (str): Root directory of the dataset.\n",
    "            task (str): Task name (e.g., 'brains').\n",
    "            fold (int or str): Fold identifier (e.g., '0').\n",
    "            resize_to (tuple): Target resize dimensions (height, width). Pass None to keep original size.\n",
    "            num_shots (int): Number of shots for few-shot learning (-1 for dense mode).\n",
    "            sparsity_mode (str): Sparsity mode ('points', 'grid', or 'dense').\n",
    "            sparsity_param (float or int): Parameter controlling sparsity (e.g., number of points or grid spacing).\n",
    "            imgtype (str): Image type (e.g., 'med').\n",
    "            make (bool): Whether to initialize and load the dataset.\n",
    "        \"\"\"\n",
    "        self.mode = mode\n",
    "        self.dataset_root = dataset_root\n",
    "        self.task = task\n",
    "        self.fold = str(fold)  # Convert fold to string\n",
    "        self.resize_to = resize_to\n",
    "        self.num_shots = num_shots\n",
    "        self.sparsity_mode = sparsity_mode\n",
    "        self.sparsity_param = sparsity_param\n",
    "        self.imgtype = imgtype\n",
    "        self.make = make\n",
    "\n",
    "        # Root directory where the dataset is stored\n",
    "        self.root = os.path.join(self.dataset_root, self.task, self.fold)\n",
    "\n",
    "        # Initialize the dataset by loading image-mask pairs\n",
    "        if make:\n",
    "            self.imgs = self.make_dataset()\n",
    "        else:\n",
    "            self.imgs = []\n",
    "\n",
    "    def make_dataset(self):\n",
    "        \"\"\"\n",
    "        Create the dataset by pairing images and masks.\n",
    "\n",
    "        Returns:\n",
    "            list: List of tuples containing paths to images and corresponding masks.\n",
    "        \"\"\"\n",
    "        data_list = []\n",
    "        mode_dir = os.path.join(self.root, \"Training\" if 'train' in self.mode.lower() else \"Testing\")\n",
    "\n",
    "        images_dir = os.path.join(mode_dir, \"images\")\n",
    "        masks_dir = os.path.join(mode_dir, \"masks\")\n",
    "\n",
    "        # Verify that the directories exist\n",
    "        if not os.path.exists(images_dir):\n",
    "            logger.error(f\"Images directory does not exist: {images_dir}\")\n",
    "            return data_list\n",
    "\n",
    "        if not os.path.exists(masks_dir):\n",
    "            logger.error(f\"Masks directory does not exist: {masks_dir}\")\n",
    "            return data_list\n",
    "\n",
    "        # Get and sort image and mask files\n",
    "        img_files = sorted(os.listdir(images_dir))\n",
    "        mask_files = sorted(os.listdir(masks_dir))\n",
    "\n",
    "        # Warn if the number of images and masks does not match\n",
    "        if len(img_files) != len(mask_files):\n",
    "            logger.warning(\"Mismatch between the number of images and masks!\")\n",
    "\n",
    "        # Pair images and masks\n",
    "        for img_file, mask_file in zip(img_files, mask_files):\n",
    "            img_path = os.path.join(images_dir, img_file)\n",
    "            mask_path = os.path.join(masks_dir, mask_file)\n",
    "\n",
    "            if os.path.exists(img_path) and os.path.exists(mask_path):\n",
    "                data_list.append((img_path, mask_path))\n",
    "            else:\n",
    "                logger.warning(f\"Missing file pair: Image={img_file}, Mask={mask_file}\")\n",
    "\n",
    "        logger.info(f\"Loaded {len(data_list)} samples for task '{self.task}' and mode '{self.mode}' from '{self.dataset_root}'\")\n",
    "        return data_list\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the total number of samples.\"\"\"\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get a single sample (image and mask) from the dataset.\n",
    "\n",
    "        Args:\n",
    "            idx (int): Index of the sample to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple containing:\n",
    "                - image (torch.Tensor): The image tensor of shape [C, H, W].\n",
    "                - y_dense (torch.Tensor): The dense mask tensor of shape [H, W].\n",
    "                - y_tr (torch.Tensor): The sparse mask tensor (after sparsity transformation).\n",
    "                - img_name (str): Name of the image file.\n",
    "        \"\"\"\n",
    "        img_path, mask_path = self.imgs[idx]\n",
    "\n",
    "        # Load image and mask\n",
    "        image = Image.open(img_path).convert('L')\n",
    "        mask = Image.open(mask_path).convert('L')\n",
    "\n",
    "        # Resize if necessary\n",
    "        if self.resize_to:\n",
    "            image = image.resize(self.resize_to, Image.BILINEAR)\n",
    "            mask = mask.resize(self.resize_to, Image.NEAREST)\n",
    "\n",
    "        # Convert image and mask to numpy arrays\n",
    "        image = np.array(image)\n",
    "        mask = np.array(mask)\n",
    "\n",
    "        # Apply sparsity transformations if specified\n",
    "        if self.sparsity_mode == 'points':\n",
    "            y_tr = self._apply_point_sparsity(mask)\n",
    "        elif self.sparsity_mode == 'grid':\n",
    "            y_tr = self._apply_grid_sparsity(mask)\n",
    "        else:\n",
    "            y_tr = mask  # Dense mask without sparsity\n",
    "\n",
    "        # Convert to PyTorch tensors\n",
    "        image = transforms.ToTensor()(image)  # Shape: [1, H, W]\n",
    "        y_dense = torch.tensor(mask, dtype=torch.long)  # Shape: [H, W]\n",
    "        y_tr = torch.tensor(y_tr, dtype=torch.long)  # Sparse mask\n",
    "\n",
    "        img_name = os.path.basename(img_path)\n",
    "        return image, y_dense, y_tr, img_name\n",
    "\n",
    "    def _apply_point_sparsity(self, mask):\n",
    "        \"\"\"\n",
    "        Apply sparsity by selecting a fixed number of points for each class.\n",
    "\n",
    "        Args:\n",
    "            mask (numpy.ndarray): Original dense mask.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Sparse mask with selected points.\n",
    "        \"\"\"\n",
    "        logger.info(f\"Applying point sparsity: {self.sparsity_param}\")\n",
    "        sparse_mask = np.zeros_like(mask)\n",
    "        num_points = self.sparsity_param if self.sparsity_param else 10\n",
    "\n",
    "        for cls in np.unique(mask):\n",
    "            if cls == 0:  # Ignore background\n",
    "                continue\n",
    "            cls_points = np.argwhere(mask == cls)\n",
    "            selected_points = cls_points[\n",
    "                np.random.choice(len(cls_points), min(num_points, len(cls_points)), replace=False)\n",
    "            ]\n",
    "            sparse_mask[tuple(zip(*selected_points))] = cls\n",
    "        return sparse_mask\n",
    "\n",
    "    def _apply_grid_sparsity(self, mask):\n",
    "        \"\"\"\n",
    "        Apply sparsity by selecting pixels at regular grid intervals.\n",
    "\n",
    "        Args:\n",
    "            mask (numpy.ndarray): Original dense mask.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Sparse mask with grid sampling.\n",
    "        \"\"\"\n",
    "        logger.info(f\"Applying grid sparsity: {self.sparsity_param}\")\n",
    "        sparse_mask = np.zeros_like(mask)\n",
    "        grid_spacing = self.sparsity_param if self.sparsity_param else 5\n",
    "        sparse_mask[::grid_spacing, ::grid_spacing] = mask[::grid_spacing, ::grid_spacing]\n",
    "        return sparse_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1747841780217,
     "user": {
      "displayName": "Deimantė Ja",
      "userId": "18204054727300762578"
     },
     "user_tz": -180
    },
    "id": "dMNuVMmKfA9i"
   },
   "outputs": [],
   "source": [
    "# The experiments parameters\n",
    "list_shots = [5]                                 # Number of shots in the task (i.e, total annotated sparse samples)\n",
    "list_sparsity_points = [1, 5, 10, 20]                       # Number of labeled pixels in point annotation\n",
    "list_sparsity_grid = [8, 12, 16, 20]                        # Spacing between selected pixels in grid annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1747841793857,
     "user": {
      "displayName": "Deimantė Ja",
      "userId": "18204054727300762578"
     },
     "user_tz": -180
    },
    "id": "2lkBfGvsX5ay"
   },
   "outputs": [],
   "source": [
    "def get_tune_loaders(shots, points, grid, fold_name, resize_to, args, imgtype='med'):\n",
    "    dataset_root = 'dataset'\n",
    "    task_name = 'brains'\n",
    "\n",
    "    loaders = {'points': [], 'grid': [], 'dense': []}\n",
    "\n",
    "    for sparsity_mode, sparsity_values in [('points', points), ('grid', grid)]:\n",
    "        for n_shots in shots:\n",
    "            for sparsity in sparsity_values:\n",
    "                tune_train_set = ListDataset(\n",
    "                    mode='tune_train',\n",
    "                    dataset_root=dataset_root,\n",
    "                    task=task_name,\n",
    "                    fold=fold_name,\n",
    "                    resize_to=resize_to,\n",
    "                    num_shots=n_shots,\n",
    "                    sparsity_mode=sparsity_mode,\n",
    "                    sparsity_param=sparsity,\n",
    "                    imgtype=imgtype\n",
    "                )\n",
    "                tune_train_loader = DataLoader(tune_train_set, batch_size=args['batch_size'], num_workers=args['num_workers'], shuffle=True)\n",
    "\n",
    "                tune_test_set = ListDataset(\n",
    "                    mode='tune_test',\n",
    "                    dataset_root=dataset_root,\n",
    "                    task=task_name,\n",
    "                    fold=fold_name,\n",
    "                    resize_to=resize_to,\n",
    "                    num_shots=-1,\n",
    "                    sparsity_mode='dense',\n",
    "                    sparsity_param=None,\n",
    "                    imgtype=imgtype\n",
    "                )\n",
    "                tune_test_loader = DataLoader(tune_test_set, batch_size=1, num_workers=args['num_workers'], shuffle=False)\n",
    "\n",
    "                loaders[sparsity_mode].append({\n",
    "                    'n_shots': n_shots,\n",
    "                    'sparsity': sparsity,\n",
    "                    'train': tune_train_loader,\n",
    "                    'test': tune_test_loader\n",
    "                })\n",
    "\n",
    "    return loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1747841797417,
     "user": {
      "displayName": "Deimantė Ja",
      "userId": "18204054727300762578"
     },
     "user_tz": -180
    },
    "id": "1BPmr2bPYI6e"
   },
   "outputs": [],
   "source": [
    "def compute_metrics_per_class(y_true, y_pred, ignore_index=0):\n",
    "    mask = y_true != ignore_index\n",
    "    y_true_filtered = y_true[mask]\n",
    "    y_pred_filtered = y_pred[mask]\n",
    "\n",
    "    classes = [1, 2, 3]\n",
    "\n",
    "    metrics_dict = {}\n",
    "    for cls in classes:\n",
    "        true_cls = y_true_filtered == cls\n",
    "        pred_cls = y_pred_filtered == cls\n",
    "\n",
    "        TP = np.sum(pred_cls & true_cls)\n",
    "        FP = np.sum(pred_cls & ~true_cls)\n",
    "        TN = np.sum(~pred_cls & ~true_cls)\n",
    "        FN = np.sum(~pred_cls & true_cls)\n",
    "\n",
    "        iou = TP / (TP + FP + FN) if (TP + FP + FN) != 0 else 0\n",
    "        dice = 2 * TP / (2 * TP + FP + FN) if (2 * TP + FP + FN) != 0 else 0\n",
    "        sensitivity = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "        specificity = TN / (TN + FP) if (TN + FP) != 0 else 0\n",
    "\n",
    "        metrics_dict[cls] = {\n",
    "            'IoU': iou,\n",
    "            'Dice': dice,\n",
    "            'Sensitivity': sensitivity,\n",
    "            'Specificity': specificity\n",
    "        }\n",
    "\n",
    "    return metrics_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 2944,
     "status": "ok",
     "timestamp": 1747841802531,
     "user": {
      "displayName": "Deimantė Ja",
      "userId": "18204054727300762578"
     },
     "user_tz": -180
    },
    "id": "bie1JpKzpl5J"
   },
   "outputs": [],
   "source": [
    "def tune_train_test(tune_train_loader, tune_test_loader, net, optimizer, args, sparsity_mode, best_weights_path):\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    net.train()\n",
    "\n",
    "    tune_train_loss_list = []\n",
    "    tune_test_loss_list = []\n",
    "\n",
    "    color_map = {\n",
    "        0: [0, 0, 0],    # Black (background)\n",
    "        1: [0, 0, 255],  # Blue (CSF)\n",
    "        2: [255, 0, 0],  # Red (GM)\n",
    "        3: [0, 255, 0]   # Green (WM)\n",
    "    }\n",
    "\n",
    "    # Funkcija konvertuoti segmentacijos žemėlapį į spalvotą vaizdą\n",
    "    def map_to_color(segmentation, color_map):\n",
    "        colored = np.zeros((segmentation.shape[0], segmentation.shape[1], 3), dtype=np.uint8)\n",
    "        for cls, color in color_map.items():\n",
    "            colored[segmentation == cls] = color\n",
    "        return colored\n",
    "\n",
    "    # Vizualizacijos funkcija\n",
    "    def visualize_segmentation(inputs, labels, preds, color_map, num_samples=3):\n",
    "        fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5 * num_samples))\n",
    "        for i in range(min(num_samples, len(inputs))):\n",
    "            # Input image\n",
    "            inp = inputs[i].numpy() if isinstance(inputs[i], torch.Tensor) else inputs[i]\n",
    "            if inp.ndim == 3 and inp.shape[0] == 1:\n",
    "                inp = inp.squeeze(0)\n",
    "            axes[i, 0].imshow(inp, cmap='gray')\n",
    "            axes[i, 0].set_title('Input Image')\n",
    "\n",
    "            # Ground truth\n",
    "            lab_colored = map_to_color(labels[i], color_map)\n",
    "            axes[i, 1].imshow(lab_colored)\n",
    "            axes[i, 1].set_title('Ground Truth')\n",
    "\n",
    "            # Prediction\n",
    "            pred_colored = map_to_color(preds[i], color_map)\n",
    "            axes[i, 2].imshow(pred_colored)\n",
    "            axes[i, 2].set_title('Prediction')\n",
    "\n",
    "            for ax in axes[i]:\n",
    "                ax.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    if os.path.exists(best_weights_path):\n",
    "        net.load_state_dict(torch.load(best_weights_path))\n",
    "        print(f\"Loaded best weights from {best_weights_path}\")\n",
    "    else:\n",
    "        print(\"No pre-saved weights found. Starting training from scratch.\")\n",
    "\n",
    "    for epoch in range(1, args['tuning_epochs'] + 1):\n",
    "        sys.stdout.flush()\n",
    "        train_loss_list = []\n",
    "\n",
    "        for i, data in enumerate(tune_train_loader):\n",
    "            x_tr, y_dense, y_tr, img_name = data\n",
    "            x_tr, y_tr = x_tr.cuda(), y_tr.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            p_tr = net(x_tr)\n",
    "            tune_train_loss = F.cross_entropy(p_tr, y_tr, ignore_index=-1)\n",
    "            tune_train_loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss_list.append(tune_train_loss.detach().item())\n",
    "\n",
    "        avg_train_loss = np.mean(train_loss_list)\n",
    "        tune_train_loss_list.append(avg_train_loss)\n",
    "\n",
    "        if epoch % args['val_freq'] == 0:\n",
    "            test_loss_list = []\n",
    "            with torch.no_grad():\n",
    "                net.eval()\n",
    "                for i, data in enumerate(tune_test_loader):\n",
    "                    x_ts, y_ts, _, img_name = data\n",
    "                    x_ts, y_ts = x_ts.cuda(), y_ts.cuda()\n",
    "                    y_ts = y_ts.long()\n",
    "                    p_ts = net(x_ts)\n",
    "                    tune_test_loss = F.cross_entropy(p_ts, y_ts, ignore_index=-1)\n",
    "                    test_loss_list.append(tune_test_loss.detach().item())\n",
    "            avg_test_loss = np.mean(test_loss_list)\n",
    "            tune_test_loss_list.append(avg_test_loss)\n",
    "            writer.add_scalar(f'{sparsity_mode}/Validation Loss', avg_test_loss, epoch)\n",
    "            net.train()\n",
    "\n",
    "    test_loss_list = []\n",
    "    inps_all, labs_all, prds_all = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        for i, data in enumerate(tune_test_loader):\n",
    "            x_ts, y_ts, _, img_name = data\n",
    "            x_ts, y_ts = x_ts.cuda(), y_ts.cuda()\n",
    "            y_ts = y_ts.long()\n",
    "            p_ts = net(x_ts)\n",
    "            tune_test_loss = F.cross_entropy(p_ts, y_ts, ignore_index=-1)\n",
    "            test_loss_list.append(tune_test_loss.detach().item())\n",
    "            prds = p_ts.detach().max(1)[1].squeeze(1).squeeze(0).cpu().numpy()\n",
    "            inps_all.append(x_ts.detach().squeeze(1).squeeze(0).cpu())\n",
    "            labs_all.append(y_ts.detach().cpu().numpy())\n",
    "            prds_all.append(prds)\n",
    "\n",
    "    avg_test_loss = np.mean(test_loss_list)\n",
    "    writer.add_scalar(f'{sparsity_mode}/Final Validation Loss', avg_test_loss, args['tuning_epochs'])\n",
    "\n",
    "    labs_np = np.asarray(labs_all).ravel()\n",
    "    prds_np = np.asarray(prds_all).ravel()\n",
    "    metrics_per_class = compute_metrics_per_class(labs_np, prds_np, ignore_index=0)\n",
    "\n",
    "    print('--------------------------------------------------------------------')\n",
    "    for cls, metrics in metrics_per_class.items():\n",
    "        print(f'Class {cls}: IoU: {metrics[\"IoU\"]*100:.2f}%, Dice: {metrics[\"Dice\"]*100:.2f}%, Sensitivity: {metrics[\"Sensitivity\"]*100:.2f}%, Specificity: {metrics[\"Specificity\"]*100:.2f}%')\n",
    "        writer.add_scalar(f'{sparsity_mode}/Final Class_{cls}_IoU', metrics[\"IoU\"], args['tuning_epochs'])\n",
    "        writer.add_scalar(f'{sparsity_mode}/Final Class_{cls}_Dice', metrics[\"Dice\"], args['tuning_epochs'])\n",
    "        writer.add_scalar(f'{sparsity_mode}/Final Class_{cls}_Sensitivity', metrics[\"Sensitivity\"], args['tuning_epochs'])\n",
    "        writer.add_scalar(f'{sparsity_mode}/Final Class_{cls}_Specificity', metrics[\"Specificity\"], args['tuning_epochs'])\n",
    "    print('--------------------------------------------------------------------')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    num_samples = min(3, len(inps_all))\n",
    "    visualize_segmentation(inps_all[:num_samples], labs_all[:num_samples], prds_all[:num_samples], color_map)\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1747841806305,
     "user": {
      "displayName": "Deimantė Ja",
      "userId": "18204054727300762578"
     },
     "user_tz": -180
    },
    "id": "uqrY0RGxM0Ui"
   },
   "outputs": [],
   "source": [
    "def tune_train_test(tune_train_loader, tune_test_loader, net, optimizer, args, sparsity_mode, best_weights_path):\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    net.train()\n",
    "\n",
    "    tune_train_loss_list = []\n",
    "    tune_test_loss_list = []\n",
    "\n",
    "    if os.path.exists(best_weights_path):\n",
    "        net.load_state_dict(torch.load(best_weights_path))\n",
    "        print(f\"Loaded best weights from {best_weights_path}\")\n",
    "    else:\n",
    "        print(\"No pre-saved weights found. Starting training from scratch.\")\n",
    "\n",
    "    for epoch in range(1, args['tuning_epochs'] + 1):\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        train_loss_list = []\n",
    "\n",
    "        for i, data in enumerate(tune_train_loader):\n",
    "            x_tr, _, y_tr, _ = data\n",
    "            x_tr, y_tr = x_tr.cuda(), y_tr.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            p_tr = net(x_tr)\n",
    "            tune_train_loss = F.cross_entropy(p_tr, y_tr, ignore_index=-1)\n",
    "            tune_train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss_list.append(tune_train_loss.detach().item())\n",
    "\n",
    "        avg_train_loss = np.mean(train_loss_list)\n",
    "        tune_train_loss_list.append(avg_train_loss)\n",
    "    \n",
    "        if epoch % args['val_freq'] == 0:\n",
    "            test_loss_list = []\n",
    "            inps_all, labs_all, prds_all = [], [], []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                net.eval()\n",
    "\n",
    "                for i, data in enumerate(tune_test_loader):\n",
    "                    x_ts, y_ts, _, _ = data\n",
    "                    x_ts, y_ts = x_ts.cuda(), y_ts.cuda()\n",
    "                    y_ts = y_ts.long()\n",
    "                    p_ts = net(x_ts)\n",
    "                    tune_test_loss = F.cross_entropy(p_ts, y_ts, ignore_index=-1)\n",
    "                    test_loss_list.append(tune_test_loss.detach().item())\n",
    "                    prds = p_ts.detach().max(1)[1].squeeze(1).squeeze(0).cpu().numpy()\n",
    "                    inps_all.append(x_ts.detach().squeeze(1).squeeze(0).cpu())\n",
    "                    labs_all.append(y_ts.detach().cpu().numpy())\n",
    "                    prds_all.append(prds)\n",
    "\n",
    "            avg_test_loss = np.mean(test_loss_list)\n",
    "            tune_test_loss_list.append(avg_test_loss)\n",
    "            writer.add_scalar(f'{sparsity_mode}/Validation Loss', avg_test_loss, epoch)\n",
    "\n",
    "            labs_np = np.asarray(labs_all).ravel()\n",
    "            prds_np = np.asarray(prds_all).ravel()\n",
    "\n",
    "            metrics_per_class = compute_metrics_per_class(labs_np, prds_np, ignore_index=0)\n",
    "\n",
    "            print('--------------------------------------------------------------------')\n",
    "            for cls, metrics in metrics_per_class.items():\n",
    "                print(f'Class {cls}: IoU: {metrics[\"IoU\"]*100:.2f}%, Dice: {metrics[\"Dice\"]*100:.2f}%, Sensitivity: {metrics[\"Sensitivity\"]*100:.2f}%, Specificity: {metrics[\"Specificity\"]*100:.2f}%')\n",
    "                # Įrašome metrikas į TensorBoard\n",
    "                writer.add_scalar(f'{sparsity_mode}/Class_{cls}_IoU', metrics[\"IoU\"], epoch)\n",
    "                writer.add_scalar(f'{sparsity_mode}/Class_{cls}_Dice', metrics[\"Dice\"], epoch)\n",
    "                writer.add_scalar(f'{sparsity_mode}/Class_{cls}_Sensitivity', metrics[\"Sensitivity\"], epoch)\n",
    "                writer.add_scalar(f'{sparsity_mode}/Class_{cls}_Specificity', metrics[\"Specificity\"], epoch)\n",
    "            print('--------------------------------------------------------------------')\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            avg_iou = np.mean([m['IoU'] for m in metrics_per_class.values()])\n",
    "            writer.add_scalar(f'{sparsity_mode}/Average IoU', avg_iou, epoch)\n",
    "\n",
    "            avg_iou = np.mean([m['IoU'] for m in metrics_per_class.values()])\n",
    "\n",
    "            net.train()\n",
    "\n",
    "    if args['tuning_epochs'] % args['val_freq'] != 0:\n",
    "        print('------------------------TESTING------------------------')\n",
    "        test_loss_list = []\n",
    "        inps_all, labs_all, prds_all = [], [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "\n",
    "            for i, data in enumerate(tune_test_loader):\n",
    "                x_ts, y_ts, _, img_name = data\n",
    "                x_ts, y_ts = x_ts.cuda(), y_ts.cuda()\n",
    "\n",
    "                y_ts = y_ts.long()\n",
    "\n",
    "                p_ts = net(x_ts)\n",
    "\n",
    "                tune_test_loss = F.cross_entropy(p_ts, y_ts, ignore_index=-1)\n",
    "                test_loss_list.append(tune_test_loss.detach().item())\n",
    "\n",
    "                prds = p_ts.detach().max(1)[1].squeeze(1).squeeze(0).cpu().numpy()\n",
    "\n",
    "                inps_all.append(x_ts.detach().squeeze(1).squeeze(0).cpu())\n",
    "                labs_all.append(y_ts.detach().cpu().numpy())\n",
    "                prds_all.append(prds)\n",
    "\n",
    "        avg_test_loss = np.mean(test_loss_list)\n",
    "        tune_test_loss_list.append(avg_test_loss)\n",
    "        writer.add_scalar(f'{sparsity_mode}/Validation Loss', avg_test_loss, args['tuning_epochs'])\n",
    "\n",
    "        labs_np = np.asarray(labs_all).ravel()\n",
    "        prds_np = np.asarray(prds_all).ravel()\n",
    "\n",
    "        metrics_per_class = compute_metrics_per_class(labs_np, prds_np, ignore_index=0)\n",
    "\n",
    "        print('--------------------------------------------------------------------')\n",
    "        for cls, metrics in metrics_per_class.items():\n",
    "            print(f'Class {cls}: IoU: {metrics[\"IoU\"]*100:.2f}%, Dice: {metrics[\"Dice\"]*100:.2f}%, Sensitivity: {metrics[\"Sensitivity\"]*100:.2f}%, Specificity: {metrics[\"Specificity\"]*100:.2f}%')\n",
    "            writer.add_scalar(f'{sparsity_mode}/Class_{cls}_IoU', metrics[\"IoU\"], args['tuning_epochs'])\n",
    "            writer.add_scalar(f'{sparsity_mode}/Class_{cls}_Dice', metrics[\"Dice\"], args['tuning_epochs'])\n",
    "            writer.add_scalar(f'{sparsity_mode}/Class_{cls}_Sensitivity', metrics[\"Sensitivity\"], args['tuning_epochs'])\n",
    "            writer.add_scalar(f'{sparsity_mode}/Class_{cls}_Specificity', metrics[\"Specificity\"], args['tuning_epochs'])\n",
    "        print('--------------------------------------------------------------------')\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1747842043060,
     "user": {
      "displayName": "Deimantė Ja",
      "userId": "18204054727300762578"
     },
     "user_tz": -180
    },
    "id": "f778IavHYTiR"
   },
   "outputs": [],
   "source": [
    "def run_sparse_tuning(loader_dict, net, optimizer, args, model_weights_dir='best_models'):\n",
    "    os.makedirs(model_weights_dir, exist_ok=True)\n",
    "\n",
    "    for dict_points in loader_dict['points']:\n",
    "\n",
    "        n_shots = dict_points['n_shots']\n",
    "        sparsity = dict_points['sparsity']\n",
    "\n",
    "        mode_identifier = f'points_{n_shots}_shots_{sparsity}_points'\n",
    "        best_weights_path = os.path.join(model_weights_dir, f'best_model_{mode_identifier}.pth')\n",
    "\n",
    "        print(f\"Evaluating 'points' ({n_shots}-shot, {sparsity}-points) with identifier '{mode_identifier}'\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        tune_train_test(dict_points['train'], dict_points['test'], net, optimizer, args, mode_identifier, best_weights_path)\n",
    "\n",
    "    for dict_grid in loader_dict['grid']:\n",
    "\n",
    "        n_shots = dict_grid['n_shots']\n",
    "        sparsity = dict_grid['sparsity']\n",
    "\n",
    "        mode_identifier = f'grid_{n_shots}_shots_{sparsity}_spacing'\n",
    "        best_weights_path = os.path.join(model_weights_dir, f'best_model_{mode_identifier}.pth')\n",
    "\n",
    "        print(f\"Evaluating 'grid' ({n_shots}-shot, {sparsity}-spacing) with identifier '{mode_identifier}'\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        tune_train_test(dict_grid['train'], dict_grid['test'], net, optimizer, args, mode_identifier, best_weights_path)\n",
    "\n",
    "    for dict_dense in loader_dict['dense']:\n",
    "\n",
    "        n_shots = dict_dense['n_shots']\n",
    "\n",
    "        mode_identifier = f'dense_{n_shots}_shots'\n",
    "        best_weights_path = os.path.join(model_weights_dir, f'best_model_{mode_identifier}.pth')\n",
    "\n",
    "        print(f\"Evaluating 'dense' ({n_shots}-shot) with identifier '{mode_identifier}'\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        tune_train_test(dict_dense['train'], dict_dense['test'], net, optimizer, args, mode_identifier, best_weights_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1747841812616,
     "user": {
      "displayName": "Deimantė Ja",
      "userId": "18204054727300762578"
     },
     "user_tz": -180
    },
    "id": "vMiZlrJfpK89"
   },
   "outputs": [],
   "source": [
    "# General arguments for training\n",
    "args = {\n",
    "    'tuning_epochs': 500,   # Number of epochs on the tuning phase.\n",
    "    'val_freq': 5,         # Test each val_freq epochs on the tuning phase.\n",
    "    'vis_freq': 25,         # Visualize predictions samples each vis_freq epochs on the tuning phase.\n",
    "    'lr': 1e-6,            # Learning rate.\n",
    "    'weight_decay': 5e-5,  # L2 penalty.\n",
    "    'momentum': 0.9,       # Momentum.\n",
    "    'num_workers': 0,      # Number of workers on data loader.\n",
    "    'batch_size': 5,       # Mini-batch size.\n",
    "    'w_size': 128,         # Width size for image resizing.\n",
    "    'h_size': 128,         # Height size for image resizing.\n",
    "    'num_channels': 1,     # Number of channels in the input\n",
    "    'num_class': 4,        # Number of classes\n",
    "}\n",
    "\n",
    "fold = 0 \n",
    "\n",
    "resize_to = (args['h_size'], args['w_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1747841842825,
     "user": {
      "displayName": "Deimantė Ja",
      "userId": "18204054727300762578"
     },
     "user_tz": -180
    },
    "id": "AvYMysYpfVTJ"
   },
   "outputs": [],
   "source": [
    "def check_mkdir(dir_name):\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.mkdir(dir_name)\n",
    "\n",
    "def prepare_meta_batch(meta_train_set, meta_test_set, index, batch_size=5):\n",
    "\n",
    "    # Acquiring training and test data.\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "\n",
    "    x_test = []\n",
    "    y_test = []\n",
    "\n",
    "    perm_train = torch.randperm(len(meta_train_set[index])).tolist()\n",
    "    perm_test = torch.randperm(len(meta_test_set[index])).tolist()\n",
    "\n",
    "    for b in range(batch_size):\n",
    "\n",
    "        d_tr = meta_train_set[index][perm_train[b]]\n",
    "        d_ts = meta_test_set[index][perm_test[b]]\n",
    "\n",
    "        x_tr = d_tr[0].cuda()\n",
    "        y_tr = d_tr[2].cuda()\n",
    "\n",
    "        x_ts = d_ts[0].cuda()\n",
    "        y_ts = d_ts[1].cuda()\n",
    "\n",
    "        x_train.append(x_tr)\n",
    "        y_train.append(y_tr)\n",
    "\n",
    "        x_test.append(x_ts)\n",
    "        y_test.append(y_ts)\n",
    "\n",
    "    x_train = torch.stack(x_train, dim=0)\n",
    "    y_train = torch.stack(y_train, dim=0)\n",
    "\n",
    "    x_test = torch.stack(x_test, dim=0)\n",
    "    y_test = torch.stack(y_test, dim=0)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def plot_kernels(kernel, idx, epoch, norm='mean0'):\n",
    "    if norm == 'mean0':\n",
    "        tensor = (1/(abs(kernel.min())*2))*kernel + 0.5\n",
    "    elif norm == '01':\n",
    "        tensor = (kernel - kernel.min()) / (kernel.max() - kernel.min())\n",
    "\n",
    "    num_kernels = tensor.shape[0]\n",
    "    num_rows = num_kernels\n",
    "    num_cols = tensor.shape[1]\n",
    "    fig = plt.figure(figsize=(16,16))\n",
    "    fig.tight_layout()\n",
    "\n",
    "    tot = num_rows * num_cols\n",
    "    pos = range(1, tot+1)\n",
    "\n",
    "    k = 0\n",
    "    for i in range(num_rows):\n",
    "        for j in range(num_cols):\n",
    "            ax1 = fig.add_subplot(num_rows,num_cols,pos[k])\n",
    "            ax1.imshow(tensor[i][j], cmap='gray')\n",
    "            ax1.axis('off')\n",
    "            ax1.set_xticklabels([])\n",
    "            ax1.set_yticklabels([])\n",
    "            k+=1\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "    plt.savefig('kernels/kernel' + str(idx) + '_ep' + str(epoch) + '.png', format='png')\n",
    "    # plt.show()\n",
    "\n",
    "def accuracy(lab, prd):\n",
    "    # Obtaining class from prediction.\n",
    "    prd = prd.argmax(1)\n",
    "\n",
    "    # Tensor to ndarray.\n",
    "    lab_np = lab.view(-1).detach().cpu().numpy()\n",
    "    prd_np = prd.view(-1).detach().cpu().numpy()\n",
    "\n",
    "    # Computing metric and returning.\n",
    "    metric_val = metrics.jaccard_score(lab_np, prd_np)\n",
    "\n",
    "    return metric_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 58,
     "status": "ok",
     "timestamp": 1747841846624,
     "user": {
      "displayName": "Deimantė Ja",
      "userId": "18204054727300762578"
     },
     "user_tz": -180
    },
    "id": "uw6NVplJfYja"
   },
   "outputs": [],
   "source": [
    "def initialize_weights(*models):\n",
    "    for model in models:\n",
    "        for module in model.modules():\n",
    "            if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear) or isinstance(module, modules.MetaConv2d) or isinstance(module, modules.MetaLinear):\n",
    "                nn.init.kaiming_normal_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    module.bias.data.zero_()\n",
    "            elif isinstance(module, nn.BatchNorm2d) or isinstance(module, modules.MetaBatchNorm2d):\n",
    "                module.weight.data.fill_(1)\n",
    "                module.bias.data.zero_()\n",
    "\n",
    "class MetaConvTranspose2d(nn.ConvTranspose2d, modules.MetaModule):\n",
    "    __doc__ = nn.ConvTranspose2d.__doc__\n",
    "\n",
    "    def forward(self, input, output_size=None, params=None):\n",
    "        if params is None:\n",
    "            params = OrderedDict(self.named_parameters())\n",
    "        weights = params.get('weight', None)\n",
    "        bias = params.get('bias', None)\n",
    "\n",
    "        if self.padding_mode != 'zeros':\n",
    "            raise ValueError('Only `zeros` padding mode is supported for ConvTranspose2d')\n",
    "\n",
    "        # Compute output padding manually\n",
    "        if output_size is not None:\n",
    "            input_size = input.size()[2:]  # Spatial dimensions\n",
    "            stride = self.stride\n",
    "            padding = self.padding\n",
    "            kernel_size = self.kernel_size\n",
    "            dilation = self.dilation\n",
    "\n",
    "            # Compute expected output size\n",
    "            expected_output_size = [\n",
    "                (input_size[i] - 1) * stride[i] - 2 * padding[i] + dilation[i] * (kernel_size[i] - 1) + 1\n",
    "                for i in range(len(input_size))\n",
    "            ]\n",
    "\n",
    "            # Compute the required output padding\n",
    "            output_padding = [\n",
    "                output_size[i] - expected_output_size[i]\n",
    "                for i in range(len(input_size))\n",
    "            ]\n",
    "        else:\n",
    "            # Use predefined output padding\n",
    "            output_padding = self.output_padding\n",
    "\n",
    "        # Perform convolution transpose\n",
    "        return F.conv_transpose2d(\n",
    "            input, weights, bias, self.stride, self.padding,\n",
    "            tuple(output_padding), self.groups, self.dilation\n",
    "        )\n",
    "\n",
    "class _MetaEncoderBlock(modules.MetaModule):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, dropout=False):\n",
    "\n",
    "        super(_MetaEncoderBlock, self).__init__()\n",
    "\n",
    "        layers = [\n",
    "            modules.MetaConv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            modules.MetaBatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            modules.MetaConv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            modules.MetaBatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        ]\n",
    "\n",
    "        if dropout:\n",
    "\n",
    "            layers.append(nn.Dropout())\n",
    "\n",
    "        layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.encode = modules.MetaSequential(*layers)\n",
    "\n",
    "    def forward(self, x, params=None):\n",
    "\n",
    "        return self.encode(x, self.get_subdict(params, 'encode'))\n",
    "\n",
    "class _MetaDecoderBlock(modules.MetaModule):\n",
    "\n",
    "    def __init__(self, in_channels, middle_channels, out_channels):\n",
    "\n",
    "        super(_MetaDecoderBlock, self).__init__()\n",
    "\n",
    "        self.decode = modules.MetaSequential(\n",
    "            nn.Dropout2d(),\n",
    "            modules.MetaConv2d(in_channels, middle_channels, kernel_size=3, padding=1),\n",
    "            modules.MetaBatchNorm2d(middle_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            modules.MetaConv2d(middle_channels, middle_channels, kernel_size=3, padding=1),\n",
    "            modules.MetaBatchNorm2d(middle_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            MetaConvTranspose2d(middle_channels, out_channels, kernel_size=2, stride=2, padding=0, output_padding=0)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, params=None):\n",
    "\n",
    "        return self.decode(x, self.get_subdict(params, 'decode'))\n",
    "\n",
    "\n",
    "class UNet(modules.MetaModule):\n",
    "\n",
    "    def __init__(self, input_channels, num_classes, prototype=False):\n",
    "\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        self.prototype = prototype\n",
    "\n",
    "        self.enc1 = _MetaEncoderBlock(input_channels, 32)\n",
    "        self.enc2 = _MetaEncoderBlock(32, 64)\n",
    "        self.enc3 = _MetaEncoderBlock(64, 128, dropout=True)\n",
    "\n",
    "        self.center = _MetaDecoderBlock(128, 256, 128)\n",
    "\n",
    "        self.dec3 = _MetaDecoderBlock(256, 128, 64)\n",
    "        self.dec2 = _MetaDecoderBlock(128, 64, 32)\n",
    "\n",
    "        self.dec1 = modules.MetaSequential(\n",
    "            nn.Dropout2d(),\n",
    "            modules.MetaConv2d(64, 32, kernel_size=3, padding=1),\n",
    "            modules.MetaBatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            modules.MetaConv2d(32, 32, kernel_size=3, padding=1),\n",
    "            modules.MetaBatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        if not self.prototype:\n",
    "            self.final = modules.MetaConv2d(32, num_classes, kernel_size=1)\n",
    "\n",
    "        initialize_weights(self)\n",
    "\n",
    "    def forward(self, x, feat=False, params=None):\n",
    "\n",
    "        enc1 = self.enc1(x, self.get_subdict(params, 'enc1'))\n",
    "        enc2 = self.enc2(enc1, self.get_subdict(params, 'enc2'))\n",
    "        enc3 = self.enc3(enc2, self.get_subdict(params, 'enc3'))\n",
    "\n",
    "        center = self.center(enc3, self.get_subdict(params, 'center'))\n",
    "\n",
    "        dec3 = self.dec3(torch.cat([center, F.interpolate(enc3, center.size()[2:], mode='bilinear')], 1), self.get_subdict(params, 'dec3'))\n",
    "        dec2 = self.dec2(torch.cat([dec3, F.interpolate(enc2, dec3.size()[2:], mode='bilinear')], 1), self.get_subdict(params, 'dec2'))\n",
    "        dec1 = self.dec1(torch.cat([dec2, F.interpolate(enc1, dec2.size()[2:], mode='bilinear')], 1), self.get_subdict(params, 'dec1'))\n",
    "\n",
    "        if self.prototype:\n",
    "            return F.interpolate(dec1, x.size()[2:], mode='bilinear')\n",
    "\n",
    "        else:\n",
    "            final = self.final(dec1, self.get_subdict(params, 'final'))\n",
    "\n",
    "            if feat:\n",
    "                return (F.interpolate(final, x.size()[2:], mode='bilinear'),\n",
    "                        dec1,\n",
    "                        F.interpolate(dec2, x.size()[2:], mode='bilinear'),\n",
    "                        F.interpolate(dec3, x.size()[2:], mode='bilinear'),\n",
    "                       )\n",
    "            else:\n",
    "                return F.interpolate(final, x.size()[2:], mode='bilinear')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 300,
     "status": "ok",
     "timestamp": 1747841850016,
     "user": {
      "displayName": "Deimantė Ja",
      "userId": "18204054727300762578"
     },
     "user_tz": -180
    },
    "id": "-3MbS_qxoOdb"
   },
   "outputs": [],
   "source": [
    "# Network and optimizer\n",
    "# from weasel.utils import *\n",
    "# from weasel.models.u_net import *\n",
    "net = UNet(args['num_channels'], num_classes=4).cuda()\n",
    "\n",
    "optimizer = optim.Adam([\n",
    "        {'params': [param for name, param in net.named_parameters() if name[-4:] == 'bias'],\n",
    "         'lr': 2 * args['lr']},\n",
    "        {'params': [param for name, param in net.named_parameters() if name[-4:] != 'bias'],\n",
    "         'lr': args['lr'], 'weight_decay': args['weight_decay']}\n",
    "    ], betas=(args['momentum'], 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RefOQOQxTHK9"
   },
   "outputs": [],
   "source": [
    "loaders_dict = get_tune_loaders(\n",
    "    shots=list_shots,\n",
    "    points=list_sparsity_points,\n",
    "    grid=list_sparsity_grid,\n",
    "    fold_name=fold,\n",
    "    resize_to=resize_to,\n",
    "    args=args,\n",
    "    imgtype='med'\n",
    ")\n",
    "\n",
    "run_sparse_tuning(loaders_dict, net, optimizer, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XrpOUoedaxrS"
   },
   "outputs": [],
   "source": [
    "# Interfare model and save images\n",
    "\n",
    "# 1. Specify the model file path\n",
    "model_path = 'SPSMM/best_model/best_model_points_5_shots_1_points_epoch_1000.pth'\n",
    "\n",
    "# 2. Initialize the model\n",
    "net = UNet(input_channels=1, num_classes=4).cuda()\n",
    "\n",
    "# 3. Load the model weights\n",
    "net.load_state_dict(torch.load(model_path, map_location='cuda'))\n",
    "net.eval()  # Set the model to evaluation mode\n",
    "\n",
    "def test_model(tune_test_loader, net):\n",
    "    # Color map for visualization\n",
    "    color_map = {\n",
    "        0: [0, 0, 0],    # Black (background)\n",
    "        1: [0, 0, 255],  # Blue (CSF)\n",
    "        2: [255, 0, 0],  # Red (GM)\n",
    "        3: [0, 255, 0]   # Green (WM)\n",
    "    }\n",
    "\n",
    "    # Helper function to convert segmentation to a colored image\n",
    "    def map_to_color(segmentation, color_map):\n",
    "        colored = np.zeros((segmentation.shape[0], segmentation.shape[1], 3), dtype=np.uint8)\n",
    "        for cls, color in color_map.items():\n",
    "            colored[segmentation == cls] = color\n",
    "        return colored\n",
    "\n",
    "    # Visualization function (updated to save all images with unique filenames)\n",
    "    def visualize_segmentation(inputs, labels, preds, color_map, img_names, dataset_type='test'):\n",
    "        # Ensure the output directory exists\n",
    "        output_dir = f'/content/drive/MyDrive/Colab Notebooks/Bakalauras/Paveiksleliai/SPSMM/'\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        # Loop over all samples (no cap)\n",
    "        for i in range(len(inputs)):\n",
    "            # Get image name (remove extension and path for cleaner filename)\n",
    "            img_name = os.path.splitext(os.path.basename(img_names[i]))[0] if img_names[i] else f\"sample_{i+1}\"\n",
    "\n",
    "            # Save input image\n",
    "            plt.figure()\n",
    "            inp = inputs[i].numpy()\n",
    "            if inp.ndim == 3 and inp.shape[0] == 1:\n",
    "                inp = inp.squeeze(0)\n",
    "            plt.imshow(inp, cmap='gray')\n",
    "            plt.axis('off')\n",
    "            save_path_input = os.path.join(output_dir, f\"test_{img_name}_input.png\")\n",
    "            plt.savefig(save_path_input, bbox_inches='tight', pad_inches=0)\n",
    "            plt.close()\n",
    "            print(f\"Saved input: {save_path_input}\")\n",
    "\n",
    "            # Save real mask\n",
    "            plt.figure()\n",
    "            lab_colored = map_to_color(labels[i], color_map)\n",
    "            plt.imshow(lab_colored)\n",
    "            plt.axis('off')\n",
    "            save_path_real_mask = os.path.join(output_dir, f\"test_{img_name}_real_mask.png\")\n",
    "            plt.savefig(save_path_real_mask, bbox_inches='tight', pad_inches=0)\n",
    "            plt.close()\n",
    "            print(f\"Saved real mask: {save_path_real_mask}\")\n",
    "\n",
    "            # Save predicted segmentation\n",
    "            plt.figure()\n",
    "            pred_colored = map_to_color(preds[i], color_map)\n",
    "            plt.imshow(pred_colored)\n",
    "            plt.axis('off')\n",
    "            save_path_segmented = os.path.join(output_dir, f\"test_{img_name}_segmented.png\")\n",
    "            plt.savefig(save_path_segmented, bbox_inches='tight', pad_inches=0)\n",
    "            plt.close()\n",
    "            print(f\"Saved segmented: {save_path_segmented}\")\n",
    "\n",
    "    # Testing loop\n",
    "    test_loss_list = []\n",
    "    inps_all, labs_all, prds_all, img_names_all = [], [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(tune_test_loader):\n",
    "            x_ts, y_ts, _, img_name = data\n",
    "            x_ts, y_ts = x_ts.cuda(), y_ts.cuda()\n",
    "            y_ts = y_ts.long()\n",
    "            p_ts = net(x_ts)\n",
    "            tune_test_loss = F.cross_entropy(p_ts, y_ts, ignore_index=-1)\n",
    "            test_loss_list.append(tune_test_loss.item())\n",
    "\n",
    "            # Process each sample in the batch\n",
    "            prds_batch = p_ts.max(1)[1].cpu().numpy()  # Shape: [batch_size, height, width]\n",
    "            print(f\"Batch {i+1} image names: {img_name}\")  # Debug: Print image names\n",
    "            for j in range(x_ts.size(0)):  # Iterate over batch_size\n",
    "                prds = prds_batch[j]  # Shape: [height, width]\n",
    "                inp = x_ts[j].squeeze(0).cpu()  # Shape: [height, width]\n",
    "                lab = y_ts[j].cpu().numpy()  # Shape: [height, width]\n",
    "                inps_all.append(inp)\n",
    "                labs_all.append(lab)\n",
    "                prds_all.append(prds)\n",
    "                img_names_all.append(img_name[j])  # Store image name\n",
    "\n",
    "    # Calculate the average test loss\n",
    "    avg_test_loss = np.mean(test_loss_list)\n",
    "    print(f'Average test loss: {avg_test_loss:.4f}')\n",
    "    print(f\"Total test images processed: {len(inps_all)}\")  # Debug: Confirm number of images\n",
    "\n",
    "    # Visualize all results (no cap)\n",
    "    visualize_segmentation(\n",
    "        inps_all,\n",
    "        labs_all,\n",
    "        prds_all,\n",
    "        color_map,\n",
    "        img_names_all,\n",
    "        dataset_type='test'\n",
    "    )\n",
    "\n",
    "# 6. Clear output directory to avoid confusion\n",
    "import shutil\n",
    "output_dir = '/content/drive/MyDrive/Colab Notebooks/Bakalauras/Paveiksleliai/SPSMM'\n",
    "if os.path.exists(output_dir):\n",
    "    shutil.rmtree(output_dir)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 7. Run the testing\n",
    "test_loader = loaders_dict['points'][0]['test']\n",
    "test_model(test_loader, net)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
